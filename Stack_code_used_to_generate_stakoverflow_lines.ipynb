{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stack_code - used to generate stakoverflow lines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXlGvS9PF+nZbo8PIhrvmy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpeter7/mlcode/blob/main/Stack_code_used_to_generate_stakoverflow_lines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1rHIc3pGE2I",
        "outputId": "1bf2eb70-06c1-4de1-ec48-08f1cc0466f9"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import copy\n",
        "from google.colab import drive\n",
        "import heapq\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/project/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncHsgvNFGBfk"
      },
      "source": [
        "def get_top_questions(url, question_count):\n",
        "    # WARNING: Only enter one of these 3 values [15, 30, 50].\n",
        "    # Since, stackoverflow, doesn't display any other size questions list\n",
        "    url = url + \"?sort=votes&pagesize={}\".format(question_count)\n",
        "    #print(url)\n",
        "    \n",
        "    # Using requests module for downloading webpage content\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parsing html data using BeautifulSoup\n",
        "    soup = bs(response.content, 'html.parser')\n",
        "    body = soup.find('body')\n",
        "\n",
        "    # Extracting Top Questions\n",
        "    question_links = body1.select(\"h3 a.question-hyperlink\")\n",
        "    error_checking(question_links, question_count)                     # Error Checking\n",
        "    questions = [i.text for i in question_links]                       # questions list\n",
        "    \n",
        "    # Extracting Summary\n",
        "    summary_divs = body1.select(\"div.excerpt\")\n",
        "    error_checking(summary_divs, question_count)                       # Error Checking\n",
        "    summaries = [i.text.strip() for i in summary_divs]                 # summaries list\n",
        "    \n",
        "    # Extracting Tags\n",
        "    tags_divs = body1.select(\"div.summary > div:nth-of-type(2)\")\n",
        "    \n",
        "    error_checking(tags_divs, question_count)                          # Error Checking\n",
        "    a_tags_list = [i.select('a') for i in tags_divs]                   # tag links\n",
        "    \n",
        "    tags = []\n",
        "\n",
        "    for a_group in a_tags_list:\n",
        "        tags.append([a.text for a in a_group])                         # tags list\n",
        "    \n",
        "    # Extracting Number of votes\n",
        "    vote_spans = body1.select(\"span.vote-count-post strong\")\n",
        "    error_checking(vote_spans, question_count)                         # Error Checking\n",
        "    no_of_votes = [int(i.text) for i in vote_spans]                    # votes list\n",
        "    \n",
        "    # Extracting Number of answers\n",
        "    answer_divs = body1.select(\"div.status strong\")\n",
        "    error_checking(answer_divs, question_count)                        # Error Checking\n",
        "    no_of_answers = [int(i.text) for i in answer_divs]                 # answers list\n",
        "    \n",
        "    # Extracting Number of views\n",
        "    div_views = body1.select(\"div.supernova\")\n",
        "    \n",
        "    error_checking(div_views, question_count)                          # Error Checking\n",
        "    no_of_views = [i['title'] for i in div_views]\n",
        "    no_of_views = [i[:-6].replace(',', '') for i in no_of_views]\n",
        "    no_of_views = [int(i) for i in no_of_views]                        # views list\n",
        "    \n",
        "    # Putting all of them together\n",
        "    df = pd.DataFrame({'question': questions, \n",
        "                       'summary': summaries, })\n",
        "    return df\n",
        "\n",
        "def error_checking(list_name, length):\n",
        "    if (len(list_name) != length):\n",
        "        print(\"Error in {} parsing, length not equal to {}!!!\".format(list_name, length))\n",
        "        return -1\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS2K00hpGZxn"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import requests # Getting Webpage content\n",
        "from bs4 import BeautifulSoup as bs # Scraping webpages\n",
        "import matplotlib.pyplot as plt # Visualization\n",
        "import matplotlib.style as style # For styling plots\n",
        "from matplotlib import pyplot as mp # For Saving plots as images\n",
        "\n",
        "# For displaying plots in jupyter notebook\n",
        "%matplotlib inline \n",
        "\n",
        "style.use('fivethirtyeight') # matplotlib Style \n",
        "f1 = open(\"movie_file_gp.txt\", \"a\")\n",
        "f2 = open(\"movie_con_gp.txt\", \"a\")\n",
        "\n",
        "for i in range(3):\n",
        "    response1 = requests.get('https://stackoverflow.com/questions?tab=votes&page={}', i)\n",
        "\n",
        "    # Parsing html data using BeautifulSoup\n",
        "    soup1 = bs(response1.content, 'html.parser')\n",
        "\n",
        "    # body \n",
        "    body1 = soup1.select_one('body')\n",
        "\n",
        "    URL2 = 'https://stackoverflow.com/questions?tab=votes&page=' + str(i)\n",
        "\n",
        "    df1 = get_top_questions(URL2, 50)\n",
        "    for j in range(50):\n",
        "        count = i*50 + j\n",
        "        str1 = str(df1.loc[j,'question'])\n",
        "        str1 = str1.replace(\"\\n\", \" \")\n",
        "        str1 = str1.replace(\"\\r\", \" \")\n",
        "        str2 = str(df1.loc[j,'summary'])\n",
        "        str2 = str2.replace(\"\\n\", \"\")\n",
        "        str2 = str2.replace(\"\\r\", \"\")\n",
        "\n",
        "        line1 = \"L99999\" + str(count)   + \" +++$+++ \" + \"u\" + str(count)   + \" +++$+++ \" + \"m\" + str(count) + \" +++$+++ \" + \"Tech\" +  \" +++$+++ \" + str1\n",
        "        line2 = \"L99999\" + str(count+1) + \" +++$+++ \" + \"u\" + str(count+1) + \" +++$+++ \" + \"m\" + str(count) + \" +++$+++ \" + \"User\" +  \" +++$+++ \" + str2\n",
        "        line3 = \"u\" + str(count) + \" +++$+++ \" + \"u\" + str(count+1) + \" +++$+++ \" + \"m\" + str(count) + \" +++$+++ \" + \"['\" + \"L99999\" + str(count) + \"', '\" + \"L99999\" + str(count+1) + \"']\"\n",
        "\n",
        "        f1.write(line1)\n",
        "        f1.write('\\n')\n",
        "        #f1.write('\\r')\n",
        "        f1.write(line2)\n",
        "        f1.write('\\n')\n",
        "        #f1.write('\\r')\n",
        "        f2.write(line3)\n",
        "        f2.write('\\n')\n",
        "\n",
        "f1.close()\n",
        "f2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvNVpBBFHtHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d35c0e3-b583-4f84-89ac-c7eda4756e17"
      },
      "source": [
        "#u30 +++$+++ u42 +++$+++ m2 +++$+++ ['L3376', 'L3377', 'L3378']\n",
        "count = 100\n",
        "valu = \"u\" + str(count) + \" +++$+++ \" + \"u\" + str(count+1) + \" +++$+++ \" + \"m\" + str(count) + \" +++$+++ \" + \"['\" + \"L99999\" + str(count) + \"', '\" + \"L99999\" + str(count+1) + \"']\"\n",
        "print(valu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "u100 +++$+++ u101 +++$+++ m100 +++$+++ ['L99999100', 'L99999101']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ApSp2J6Q0CO"
      },
      "source": [
        "count = 100\n",
        "x = str(count)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}